{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 215,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ziBW4KOT2lQ",
        "outputId": "e6a3a2c2-4450-4364-8e6f-efe0a99457ee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
            ]
          },
          "metadata": {},
          "execution_count": 215
        }
      ],
      "source": [
        "# read in all the words\n",
        "words = open('names.txt', 'r').read().splitlines()\n",
        "words[:8]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# build the vocabulary of characters and mappings to/from integers\n",
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i:s for s,i in stoi.items()}\n",
        "vocab_size = len(itos)\n",
        "print(itos)\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhPNe6xKUHBU",
        "outputId": "60dbdd07-beca-46f1-ed12-2c46e8dffae7"
      },
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
            "27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jax.numpy as jnp\n",
        "from jax import grad, value_and_grad, jit, vmap\n",
        "from jax import random as jrandom\n",
        "from jax import nn\n",
        "import numpy as np\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "_X2Ik4V_VAgk"
      },
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build the dataset\n",
        "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
        "\n",
        "def build_dataset(words):\n",
        "  X, Y = [], []\n",
        "\n",
        "  for w in words:\n",
        "    context = [0] * block_size\n",
        "    for ch in w + '.':\n",
        "      ix = stoi[ch]\n",
        "      X.append(context)\n",
        "      Y.append(ix)\n",
        "      context = context[1:] + [ix] # crop and append\n",
        "\n",
        "  X = jnp.array(X)\n",
        "  Y = jnp.array(Y)\n",
        "  print(X.shape, Y.shape)\n",
        "  return X, Y\n",
        "\n",
        "import random as prandom\n",
        "prandom.seed(42)\n",
        "prandom.shuffle(words)\n",
        "n1 = int(0.8*len(words))\n",
        "n2 = int(0.9*len(words))\n",
        "\n",
        "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
        "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
        "Xte,  Yte  = build_dataset(words[n2:])     # 10%\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbjCyNmpUw-F",
        "outputId": "3cf06ba3-a2df-4f04-f5f1-74c8f8b6413e"
      },
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(182625, 3) (182625,)\n",
            "(22655, 3) (22655,)\n",
            "(22866, 3) (22866,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "key, *g = jrandom.split(jrandom.key(43), 6)\n",
        "\n",
        "C = jrandom.normal(g[0], (27, 10)) * 0.01\n",
        "W1 = jrandom.normal(g[1], (30, 200)) * 0.01\n",
        "b1 = jrandom.normal(g[2], 200) * 0.01\n",
        "W2 = jrandom.normal(g[3], (200, 27)) * 0.01\n",
        "b2 = jrandom.normal(g[4], 27) * 0.01\n",
        "parameters = [C, W1, b1, W2, b2]"
      ],
      "metadata": {
        "id": "jYl3j548Xml2"
      },
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(np.prod(list(p.shape)) for p in parameters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fNdNubRZb0o",
        "outputId": "ca162492-2c33-4169-f669-6c0024b3de04"
      },
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.int64(11897)"
            ]
          },
          "metadata": {},
          "execution_count": 220
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lri = []\n",
        "lossi = []\n",
        "stepi = []"
      ],
      "metadata": {
        "id": "Pr-HUPz0bm5C"
      },
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy_loss(logits, targets):\n",
        "    log_probs = nn.log_softmax(logits)\n",
        "    nll = -jnp.take_along_axis(log_probs, targets[:, jnp.newaxis], axis=1)\n",
        "    return jnp.mean(nll)"
      ],
      "metadata": {
        "id": "-51-RGbXeSZl"
      },
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@jit\n",
        "def forward(parameters, X):\n",
        "  C, W1, b1, W2, b2 = parameters\n",
        "  emb = C[X] # (32, 3, 10)\n",
        "  h = jnp.tanh(emb.reshape(-1, 30) @ W1 + b1) # (32, 200)\n",
        "  logits = h @ W2 + b2 # (32, 27)\n",
        "  return logits"
      ],
      "metadata": {
        "id": "Vbq92flYhadl"
      },
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@jit\n",
        "def calc_loss(parameters, X, targets):\n",
        "    logits = forward(parameters, X)\n",
        "    log_probs = nn.log_softmax(logits)\n",
        "    nll = -jnp.take_along_axis(log_probs, targets[:, jnp.newaxis], axis=1)\n",
        "    return jnp.mean(nll)"
      ],
      "metadata": {
        "id": "PmSX0WXYh95d"
      },
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tqdm(total=5000) as pbar:\n",
        "  for i in range(5000):\n",
        "\n",
        "    # minibatch construct\n",
        "    key, ix_key = jrandom.split(key)\n",
        "    ix = jrandom.randint(ix_key, (32,), 0, Xtr.shape[0])\n",
        "\n",
        "    # forward pass\n",
        "    loss, grads = value_and_grad(calc_loss)(parameters, Xtr[ix], Ytr[ix])\n",
        "    # print(loss.item())\n",
        "    # print(grads)\n",
        "\n",
        "    # update\n",
        "    #lr = lrs[i]\n",
        "    lr = jnp.array(0.1)\n",
        "\n",
        "    for j in range(len(parameters)):\n",
        "      parameters[j] += -lr * grads[j]\n",
        "\n",
        "    # track stats\n",
        "    #lri.append(lre[i])\n",
        "    stepi.append(i)\n",
        "    lossi.append(jnp.log10(loss).item())\n",
        "\n",
        "    pbar.update(1)\n",
        "    if i % 100 == 0:\n",
        "      pbar.set_postfix(loss=loss.item())\n",
        "\n",
        "    # break\n",
        "\n",
        "  #print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCtKAvaWbpBO",
        "outputId": "5f45a71e-351d-41d2-e6be-e29d5faf830e"
      },
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5000/5000 [00:50<00:00, 98.68it/s, loss=2.48]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss = calc_loss(parameters, Xdev, Ydev)\n",
        "val_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGGmT0TWJFoW",
        "outputId": "7249fb53-4c1f-4c46-c933-7bfda0eb0831"
      },
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array(2.436199, dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 226
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(10):\n",
        "    out = []\n",
        "    context = [0] * block_size # initialize with all ...\n",
        "    while True:\n",
        "      logits = forward(parameters, jnp.array([context]))\n",
        "      probs = nn.softmax(logits, axis=1)\n",
        "      key, key_split = jrandom.split(key)\n",
        "      ix = jnp.argmax(jrandom.multinomial(key_split, 1, probs), axis=1).item()\n",
        "      context = context[1:] + [ix]\n",
        "      out.append(ix)\n",
        "      if ix == 0:\n",
        "        break\n",
        "\n",
        "    print(''.join(itos[i] for i in out))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jphl54U-KdAT",
        "outputId": "58b4b5fa-21df-439d-be7a-ac3be34ad7e6"
      },
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nainn.\n",
            "ala.\n",
            "ayrlya.\n",
            "dat.\n",
            "biunan.\n",
            "yley.\n",
            "kiya.\n",
            "cabin.\n",
            "hadyna.\n",
            "raqa.\n"
          ]
        }
      ]
    }
  ]
}